---
layout: post
title: "It's a sign! ü§ü"
subtitle : How sign languages are represented in various media
tags: []
image: https://images.pexels.com/photos/267669/pexels-photo-267669.jpeg?auto=compress&cs=tinysrgb&dpr=3&h=750&w=1260
displayimage: 
author: Jennie Ablog
comments : true
final: true
---

<strong>Sign languages are more than just gestures and expressions, they are natural languages with a grammar and lexicon of their own.</strong> There are at least [144](https://www.ethnologue.com/subgroups/sign-language) sign languages that are existing around the world as of today. Sign languages are in so many ways different from other natural languages as they are composed of <strong>signs</strong>‚Å†‚Äîcombinations of <strong>manual</strong> elements (hand shape, orientation, movement, etc.) and <strong>non-manual</strong> elements (limbic postures, mouth gestures, facial expressions, etc.). Like any other natural language, sign languages <strong>continue to evolve</strong>. They are constantly being documented and studied in various disciplines. Researchers have devised multiple ways to represent sign languages to study it more closely and make signed content more accessible for both hearing people and the Deaf.<br><br>

<!-- manual and nonmanual components of sign -->


<h4>Written Representation of Signs</h4>
[Several notation systems](https://aslfont.github.io/Symbol-Font-For-ASL/ways-to-write.html) have been developed to enable the <strong>transcription of signs</strong>, or the process of coverting signs into written symbols. Among them are [SignWriting](http://signwriting.com/) and [HamNoSys](https://www.sign-lang.uni-hamburg.de/dgs-korpus/index.php/hamnosys-97.html). These notation systems have widely been used for sign language studies and are available for computer use. They are visually iconic and have a lot of different symbols to represent both manual and non-manual components of a sign. As a result, these written representations can be quite complex and can become extremely difficult to process for people who are unfamiliar with them.<br><br>

<!-- sample hamnosys representation -->

Written representations of sign are of not much use for the Deaf who naturally prefer actual signed content over complex notations that need some getting used to.<br><br>

<h4>Signed Content Videos</h4>
Never having heard sound makes it much harder for the the Deaf to learn to speak or read English or any other spoken/written language [(Azbel, 2004)](http://psych.nyu.edu/pelli/docs/azbel2004intel.pdf). Because society has become more and more dependent on technology, information are now usually obtained through digital means. However, the same information flashed through the screens of people's devices are by default, <strong>made by hearing people for hearing people</strong> and without giving much consideration to deaf users. The lack of signed content on various digital platforms makes a plethora of available information  <strong>inaccessible to the Deaf</strong>. To resolve this, signed content are now being inserted in the form of live or pre-recorded videos of <strong>human sign language interpreters</strong> signing spoken or written information contained in these digital platforms.<br><br>

<!-- signed content in tv -->


<h4>Automatically Generated Signed Content</h4>
Because of the costs of creating and maintaining signed content using human sign language interpreters, studies have proposed alternative ways of automating signed content generation, like generating signed content through [avatar animation](http://vh.cmp.uea.ac.uk/index.php/JASigning). <!-- An [example]() of such system takes in [HamNoSys]() transciptions of a sign and converts it into [SiGML]() data which is fed into an [avatar signing applet]() to produce a synthetic animation for the sign.
 --> Automatically generated signed content is a lot less expensive to produce and maintain than signed content videos of human interpreters. It is indeed no match for the natural way of signing, but with constant research and development, it could be come the better choice as a means for including signed content in digital platforms.<br><br>

<h2>Up next: Creating sign language dictionaries</h2>







<!-- <h4>Sign Language Dictionaries</h4>
Many sign language dictionaries can now be found online. These are composed of type-written text and their sign equivalent in the form of videos of humans signing the text. However, this approach of providing signed content for individual words is generally <strong>expensive</strong> to maintain for the following reasons:
 <strong>(1)</strong> a large amount of memory is required on the server side to store signed content, 
 <strong>(2)</strong> bandwidth affects the quality of transmitted signed content which may affect intelligibility of the sign, and
 <strong>(3)</strong> actual humans are needed to sign which is time-and-space consuming.<br><br>



<h4>Synthetic Sign Animations</h4>
Because of the difficulties previously referenced, several alternative solutions have been presented by different studies. One of these is to provide signed content through <strong>synthetic animation</strong>.<br><br>





<h4>A System for Creating HamNoSys-based Dictionaries</h4>
In 2016, Kaur, K. and Kumar, P. proposed a system for creating an HamNoSys-based Indian Sign Language HamNoSys-based dictionary. The proposed system stores sign language data in terms of <strong>sign gloss</strong> and its corresponding <strong>HamNoSys transcription</strong>. From HamNoSys transcriptions, the system generates <strong>SiGML</strong> which is used to produce animation data for a signing avatar.

<br> -->